{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Installs"
      ],
      "metadata": {
        "id": "DWALeR1X93PN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVO2Y-Jqbkdx",
        "outputId": "b1604a80-0e75-40fb-f731-e82d0287d8c9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.8/15.8 MB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 KB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.8/57.8 KB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 KB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 KB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.1/57.1 KB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 KB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.9/66.9 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.6/69.6 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 KB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.6/80.6 KB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import urllib.request\n",
        "import sqlite3\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "5sti32f8f9gZ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model loading and setup"
      ],
      "metadata": {
        "id": "bP7n3tQq92sU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Clone the repository to get the saved model\n",
        "urllib.request.urlretrieve('https://github.com/CNielsen94/NN_exercises_AAUBSDS/raw/main/MLOps_assignments/Assignment_one/model.pth', 'model.pth')\n",
        "\n",
        "# Load the saved model state dictionary\n",
        "model_state_dict = torch.load('model.pth', map_location=torch.device('cpu'))\n",
        "\n",
        "# Define the model architecture\n",
        "model_net1 = torch.nn.Sequential(torch.nn.Linear(3,2),\n",
        "                                 torch.nn.ReLU(),\n",
        "                                 torch.nn.Linear(2,1),\n",
        "                                 torch.nn.Sigmoid())\n",
        "\n",
        "# Load the saved model state dictionary into the model architecture\n",
        "model_net1.load_state_dict(model_state_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFk5sNVAbqon",
        "outputId": "e6dfeb06-871c-42a2-b2c1-21db26c57450"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First gradio interface for prediction (No DB implemented, and possibly faulty)"
      ],
      "metadata": {
        "id": "9keDy3K1-ecM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def first_predict(TotalWorkingYear_tier, EnvironmentSatisfaction, YearsAtCompany_tier):\n",
        "    inputs = torch.tensor([int(TotalWorkingYear_tier), int(EnvironmentSatisfaction), int(YearsAtCompany_tier)])\n",
        "    output = model_net1(inputs.float())\n",
        "    prediction = output.item()\n",
        "    if prediction < 0.5:\n",
        "        return \"No Attrition\"\n",
        "    else:\n",
        "        return \"Attrition\""
      ],
      "metadata": {
        "id": "gBxnRWPUe9A4"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(1,2,5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "l48LC0eYgvNB",
        "outputId": "fec72c91-6a5e-4f3e-ad72-1cba3f7977c4"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'No'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = [\n",
        "    gr.inputs.Slider(minimum=0, maximum=5, step=1, default=2, label=\"TotalWorkingYear_tier\"),\n",
        "    gr.inputs.Slider(minimum=1, maximum=4, step=1, default=2, label=\"EnvironmentSatisfaction\"),\n",
        "    gr.inputs.Slider(minimum=0, maximum=5, step=1, default=2, label=\"YearsAtCompany_tier\")\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRlWCR9We894",
        "outputId": "0952a1b6-eab9-4bed-cede-9e47199169c3"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:89: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = gr.outputs.Label(num_top_classes=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgnfasJve80x",
        "outputId": "b2dd47d1-b678-4819-e88f-d559e66fc5a0"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:197: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
            "  warnings.warn(value)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gr.Interface(fn=first_predict, inputs=inputs, outputs=outputs, title=\"Attrition Predictor\").launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "jr77J6QJgDOQ",
        "outputId": "8079e4da-a128-4082-eb5d-6b193e8df7a2"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7888, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So our predictions seem to always be zero, which is most likely due to overfitting and or just a too simple network. Let's integrate some database fetching for individual employees anyways:"
      ],
      "metadata": {
        "id": "sitwDGCzkDKn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second interface with DB interaction"
      ],
      "metadata": {
        "id": "GEU2Pifk-uBc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fetching HR_DB.db from repository:"
      ],
      "metadata": {
        "id": "ALeTwpV4-y10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://github.com/CNielsen94/NN_exercises_AAUBSDS/raw/main/MLOps_assignments/Assignment_one/HR_DB.db'\n",
        "filename = 'HR_DB.db'\n",
        "\n",
        "urllib.request.urlretrieve(url, filename)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94DUnwtAhcqQ",
        "outputId": "461d0c48-ce69-4f89-bbf0-e75d26dcac97"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('HR_DB.db', <http.client.HTTPMessage at 0x7fa7c423c670>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_attrition(EmployeeID):\n",
        "\n",
        "    # Create a new connection and cursor object\n",
        "    conn = sqlite3.connect('HR_DB.db')\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # Get the Employee's TotalWorkingYears_tier and YearsAtCompany_tier from EmployeeTiers table\n",
        "    cursor.execute(f\"SELECT TotalWorkingYear_tier, YearsAtCompany_tier FROM EmployeeTiers WHERE EmployeeID={EmployeeID}\")\n",
        "    tiers = cursor.fetchone()\n",
        "\n",
        "    # Get the Employee's EnvironmentSatisfaction from EmployeeSurvey table\n",
        "    cursor.execute(f\"SELECT EnvironmentSatisfaction FROM employee_survey WHERE EmployeeID={EmployeeID}\")\n",
        "    env_satisfaction = cursor.fetchone()\n",
        "\n",
        "    # Convert the fetched data into a tensor\n",
        "    inputs = torch.tensor([tiers[0], env_satisfaction[0], tiers[1]], dtype=torch.float)\n",
        "\n",
        "    # Make the prediction using the loaded model\n",
        "    output = model_net1(inputs).item()\n",
        "    prediction = \"Attrition\" if output > 0.5 else \"No Attrition\"\n",
        "    message = f\"The predicted Attrition for EmployeeID {EmployeeID} is: {prediction}\"\n",
        "\n",
        "    # Close the cursor and connection objects\n",
        "    cursor.close()\n",
        "    conn.close()\n",
        "\n",
        "    return prediction"
      ],
      "metadata": {
        "id": "7Tv2eO3ej2Y_"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#query = 'SELECT * FROM EmployeeTiers'\n",
        "#df = pd.read_sql(query, conn)"
      ],
      "metadata": {
        "id": "GmXyfulNmyVf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quick test for predictions. Our model is seemingly bad at predicting the results, as all employees seem to love the workplace."
      ],
      "metadata": {
        "id": "GMZphJRD_Vpi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(predict_attrition(382))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EF97Cfbmm6X",
        "outputId": "2d38bc4a-0cdb-4cf2-d0d9-366997ab1746"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No Attrition\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=predict_attrition, \n",
        "    inputs=gr.inputs.Number(label=\"Employee ID\"), \n",
        "    outputs=gr.outputs.Textbox(label=\"Attrition Prediction\"),\n",
        "    title=\"Employee Attrition Prediction\",\n",
        "    description=\"Enter an EmployeeID to predict their likelihood of attrition.\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivQ8Jr4ojzEo",
        "outputId": "191bffa3-0b47-4e71-d15d-563f17c0a5cc"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/gradio/inputs.py:59: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
            "  warnings.warn(value)\n",
            "/usr/local/lib/python3.9/dist-packages/gradio/outputs.py:22: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "iface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 616
        },
        "id": "x2W6Ax0XopL_",
        "outputId": "e6e9282c-238f-4723-f5d5-62b50efdcb62"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "                        if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "                            return;\n",
              "                        }\n",
              "                        element.appendChild(document.createTextNode(''));\n",
              "                        const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "\n",
              "                        const external_link = document.createElement('div');\n",
              "                        external_link.innerHTML = `\n",
              "                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n",
              "                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n",
              "                                    https://localhost:${port}${path}\n",
              "                                </a>\n",
              "                            </div>\n",
              "                        `;\n",
              "                        element.appendChild(external_link);\n",
              "\n",
              "                        const iframe = document.createElement('iframe');\n",
              "                        iframe.src = new URL(path, url).toString();\n",
              "                        iframe.height = height;\n",
              "                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n",
              "                        iframe.width = width;\n",
              "                        iframe.style.border = 0;\n",
              "                        element.appendChild(iframe);\n",
              "                    })(7889, \"/\", \"100%\", 500, false, window.element)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    }
  ]
}
